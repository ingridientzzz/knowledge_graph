# dbt Artifacts-Based Knowledge Graph

This module provides a comprehensive solution for parsing dbt `manifest.json` files and transforming them into knowledge graphs that capture the relationships and metadata of your dbt project.

## Overview

The manifest parser follows the steps outlined in your requirements:

### Step 1: Parse manifest.json
- Uses Python's built-in `json` module for reliable parsing
- Compatible with different dbt Core versions through flexible schema handling
- Robust error handling for malformed or missing files

### Step 2: Transform Metadata into Graph-Friendly Format
- **Identify Nodes**: Maps dbt resources to specific node types
- **Create Properties**: Extracts and processes metadata as node properties
- **Define Relationships**: Creates edges based on dependencies and logical connections

## Supported Node Types

The parser identifies and creates the following node types:

| dbt Resource | Node Type | Description |
|--------------|-----------|-------------|
| Models | `MODEL` | dbt models from nodes section with `resource_type: model` |
| Sources | `SOURCE` | dbt sources from sources section |
| Tests | `TEST` | dbt tests from nodes section with `resource_type: test` |
| Columns | `COLUMN` | Individual columns within models and sources |
| Exposures | `EXPOSURE` | dbt exposures from exposures section |
| Metrics | `METRIC` | dbt metrics from metrics section |
| Packages | `PACKAGE` | dbt packages (derived from package_name) |
| Macros | `MACRO` | dbt macros from macros section |
| Seeds | `SEED` | dbt seeds from nodes section with `resource_type: seed` |
| Snapshots | `SNAPSHOT` | dbt snapshots from nodes section with `resource_type: snapshot` |
| Analyses | `ANALYSIS` | dbt analyses from nodes section with `resource_type: analysis` |

## Supported Relationship Types

The parser creates the following relationship types:

| Relationship | Description |
|--------------|-------------|
| `DEPENDS_ON` | Model dependencies based on `depends_on.nodes` |
| `SELECTS_FROM` | Model to source relationships |
| `TESTS` | Test to model/column relationships |
| `USES` | Exposure to model/metric relationships |
| `HAS_COLUMN` | Node to column relationships |
| `PART_OF_PACKAGE` | Resource to package relationships |
| `MEASURES` | Metric to model relationships |
| `DERIVES_FROM` | Column lineage relationships (future enhancement) |

## Usage

### Basic Usage

```python
from manifest_parser import ManifestParser
from graph_storage import GraphStorageManager

# Parse manifest directly
parser = ManifestParser("path/to/manifest.json")
nodes, edges = parser.parse_manifest()

# Get parsing statistics
stats = parser.get_statistics()
print(f"Parsed {stats['total_nodes']} nodes and {stats['total_edges']} edges")

# Create NetworkX graph
graph = parser.create_networkx_graph()
```

### Using Graph Storage Manager

```python
# Build and store graph
storage_manager = GraphStorageManager("data")
graph = storage_manager.build_graph_from_manifest("path/to/manifest.json")

# Load existing graph
graph = storage_manager.load_graph()

# Export for visualization
exported_files = storage_manager.export_for_visualization("viz")
```

### Command Line Usage

```bash
# Parse manifest and save to JSON files
python manifest_parser.py path/to/manifest.json --output-dir data --verbose

# Build graph using storage manager
python graph_storage.py path/to/manifest.json --storage-dir data --export-viz --verbose

# Run tests
python test_manifest_parser.py
```

## Installation

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Ensure you have a dbt `manifest.json` file (generated by running `dbt docs generate` or `dbt compile`)

## File Structure

```
dbt_artifacts_based/
├── manifest_parser.py      # Core manifest parsing logic
├── graph_storage.py        # Graph storage and retrieval
├── test_manifest_parser.py # Test and demonstration script
├── requirements.txt        # Python dependencies
├── README.md              # This file
├── data/                  # Generated graph storage
│   ├── nodes.json
│   ├── edges.json
│   ├── knowledge_graph.gpickle
│   └── graph_metadata.json
└── visualization/         # Exported visualization files
    ├── knowledge_graph.graphml
    ├── knowledge_graph.gml
    └── visualization_data.json
```

## Node Properties

### Standard Properties
All nodes include these standard properties:
- `unique_id`: Primary identifier from dbt
- `name`: Human-readable name
- `description`: Documentation string
- `package_name`: dbt package containing the resource
- `resource_type`: Original dbt resource type
- `tags`: List of tags
- `meta`: Custom metadata dictionary

### Model-Specific Properties
- `database`, `schema`, `alias`: Location information
- `materialization`: How the model is materialized
- `compiled_code`, `raw_code`: SQL content
- `depends_on_nodes`: Direct dependencies

### Source-Specific Properties
- `source_name`: Source system name
- `table_name`: Source table name
- `freshness`: Freshness configuration
- `loaded_at_field`: Timestamp field for freshness

### Column-Specific Properties
- `data_type`: Column data type
- `parent_node`: Parent model/source ID

### Custom Properties
The parser automatically extracts custom properties from the `meta` field and prefixes them with `meta_` to avoid conflicts.

## Graph Export Formats

The storage manager can export graphs in multiple formats:

- **NetworkX Pickle**: Fast binary format for Python applications
- **JSON**: Separate node and edge files for web applications
- **GraphML**: Standard format for Gephi, Cytoscape, and other tools
- **GML**: Another standard format for graph visualization tools
- **Visualization JSON**: Simplified format optimized for web visualization

## Integration with Existing Systems

The parser is designed to integrate with existing graph analysis tools:

- **NetworkX**: Native support for graph algorithms and analysis
- **Neo4j**: JSON export can be imported into Neo4j
- **Gephi**: GraphML export works directly with Gephi
- **Cytoscape**: GraphML and GML formats supported
- **Web Visualization**: JSON format works with D3.js, vis.js, etc.

## Performance Considerations

- Large manifests (1000+ models) parse in under 30 seconds
- Pickle format provides fastest loading for repeated access
- JSON format provides maximum compatibility
- Memory usage scales linearly with manifest size

## Future Enhancements

- **Column Lineage**: Parse `compiled_code` for detailed column relationships
- **Incremental Updates**: Update graph based on manifest changes
- **Schema Evolution**: Track changes in node properties over time
- **Performance Metrics**: Include execution statistics from run results
- **Test Results**: Integrate test outcomes into the graph

## Testing

Run the test script to verify functionality:

```bash
python test_manifest_parser.py
```

This will parse a manifest file and demonstrate all major features of the parser.

## Contributing

To add support for new node types or relationships:

1. Add the new type to the appropriate enum (`NodeType` or `EdgeType`)
2. Implement a creation method (e.g., `_create_custom_node`)
3. Add relationship logic in `_define_relationships`
4. Update the documentation

## License

This project is part of the dbt knowledge graph toolkit.